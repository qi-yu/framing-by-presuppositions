{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning BERT on 200-Word Sequences of German News Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook fine-tunes [bert-base-german-cased](https://huggingface.co/bert-base-german-cased) on a source classification task, i.e., classifying whether a text sequence is from BILD, FAZ or SZ. We divided each raw article from the corpus into segments of maximally 200 words long, in order to circumvent the limitation of BERT that the input cannot be longer than 512 tokens. For more details, we refer to Section 4.2, Paragraph *Vectorizing iterAdv-S* of the original paper. \n",
    "\n",
    "The code for fine-tuning BERT is based on [this tutorial](http://mccormickml.com/2019/07/22/BERT-fine-tuning/) by Chris McCormick and Nick Ryan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 GPU(s) available.\n",
      "We will use the GPU: Quadro RTX 5000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries: \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import statistics\n",
    "import gc\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig, get_linear_schedule_with_warmup, BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length_distribution(df):\n",
    "    \"\"\"\n",
    "    Get statistics of the lengths of the articles in each newspaper.\n",
    "    \"\"\"\n",
    "    \n",
    "    length = []\n",
    "    for text in df['text_cleaned']:\n",
    "        length.append(len(text.split()))\n",
    "        \n",
    "    print(pd.Series(length).describe())\n",
    "\n",
    "    plt.hist(length, bins = [i*100 for i in range(1, max(length)//100 + 2)])\n",
    "    print(\"Average length of the texts:\", statistics.mean(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text=re.sub(\"\\W+\",\" \",text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split(text1):\n",
    "    \"\"\"\n",
    "    Split each raw text into sequences with maximally 200 word long.\n",
    "    \"\"\"\n",
    "    \n",
    "    l_total = []\n",
    "    l_parcial = []\n",
    "    if len(text1.split())//150 >0:\n",
    "        n = len(text1.split())//150\n",
    "    else: \n",
    "        n = 1\n",
    "    \n",
    "    for w in range(n):\n",
    "        if w == 0:\n",
    "            l_parcial = text1.split()[:200]\n",
    "            l_total.append(\" \".join(l_parcial))\n",
    "        else:\n",
    "            l_parcial = text1.split()[w*150:w*150 + 200]\n",
    "            l_total.append(\" \".join(l_parcial))\n",
    "    return l_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23370, 2)\n",
      "0    12109\n",
      "1     6700\n",
      "2     4561\n",
      "Name: source, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Sehen gut aus und tun Gutes. Die Bremer Kult-T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Jahrelang war eine Rückkehr der Wohnschiffe fü...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Man kann's ja mal versuchen... Die Chemnitzer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Jetzt wird es Ernst an der ehemaligen Gerhart-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Im Streit um die besetzte Flüchtlings-Schule i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source                                       text_cleaned\n",
       "0       0  Sehen gut aus und tun Gutes. Die Bremer Kult-T...\n",
       "1       0  Jahrelang war eine Rückkehr der Wohnschiffe fü...\n",
       "2       0  Man kann's ja mal versuchen... Die Chemnitzer ...\n",
       "3       0  Jetzt wird es Ernst an der ehemaligen Gerhart-...\n",
       "4       0  Im Streit um die besetzte Flüchtlings-Schule i..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.read_csv(\"/work/qi.yu/data/clean/corpus_cleaned_2022-01-26.tsv\", sep=\"\\t\", encoding=\"utf-8\")\n",
    "df = df_raw.iloc[:, np.r_[0,2]]\n",
    "print(df.shape)\n",
    "print(df[\"source\"].value_counts())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    23370.000000\n",
      "mean       301.223192\n",
      "std        317.989437\n",
      "min          1.000000\n",
      "25%         91.000000\n",
      "50%        185.000000\n",
      "75%        402.000000\n",
      "max       4331.000000\n",
      "dtype: float64\n",
      "Average length of the texts: 301.2231921266581\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_length_distribution(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    12109.000000\n",
      "mean       215.762738\n",
      "std        258.038676\n",
      "min          1.000000\n",
      "25%         78.000000\n",
      "50%        138.000000\n",
      "75%        252.000000\n",
      "max       4331.000000\n",
      "dtype: float64\n",
      "Average length of the texts: 215.76273845899743\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_bild = df[df.source==0]\n",
    "get_length_distribution(df_bild)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    6700.000000\n",
      "mean      433.278060\n",
      "std       374.360268\n",
      "min        10.000000\n",
      "25%       160.000000\n",
      "50%       330.000000\n",
      "75%       599.000000\n",
      "max      3736.000000\n",
      "dtype: float64\n",
      "Average length of the texts: 433.2780597014925\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_faz = df[df.source==1]\n",
    "get_length_distribution(df_faz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    4561.000000\n",
      "mean      334.126727\n",
      "std       299.034267\n",
      "min        15.000000\n",
      "25%        97.000000\n",
      "50%       240.000000\n",
      "75%       479.000000\n",
      "max      2649.000000\n",
      "dtype: float64\n",
      "Average length of the texts: 334.12672659504494\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_sz = df[df.source==2]\n",
    "get_length_distribution(df_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Sehen gut aus und tun Gutes Die Bremer Kult Ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Jahrelang war eine Rückkehr der Wohnschiffe fü...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Man kann s ja mal versuchen Die Chemnitzer Woh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Jetzt wird es Ernst an der ehemaligen Gerhart ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Im Streit um die besetzte Flüchtlings Schule i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source                                       text_cleaned\n",
       "0       0  Sehen gut aus und tun Gutes Die Bremer Kult Ta...\n",
       "1       0  Jahrelang war eine Rückkehr der Wohnschiffe fü...\n",
       "2       0  Man kann s ja mal versuchen Die Chemnitzer Woh...\n",
       "3       0  Jetzt wird es Ernst an der ehemaligen Gerhart ...\n",
       "4       0  Im Streit um die besetzte Flüchtlings Schule i..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_cleaned'] = df[\"text_cleaned\"].apply(clean_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>text_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Sehen gut aus und tun Gutes Die Bremer Kult Ta...</td>\n",
       "      <td>[Sehen gut aus und tun Gutes Die Bremer Kult T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Jahrelang war eine Rückkehr der Wohnschiffe fü...</td>\n",
       "      <td>[Jahrelang war eine Rückkehr der Wohnschiffe f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Man kann s ja mal versuchen Die Chemnitzer Woh...</td>\n",
       "      <td>[Man kann s ja mal versuchen Die Chemnitzer Wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Jetzt wird es Ernst an der ehemaligen Gerhart ...</td>\n",
       "      <td>[Jetzt wird es Ernst an der ehemaligen Gerhart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Im Streit um die besetzte Flüchtlings Schule i...</td>\n",
       "      <td>[Im Streit um die besetzte Flüchtlings Schule ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source                                       text_cleaned  \\\n",
       "0       0  Sehen gut aus und tun Gutes Die Bremer Kult Ta...   \n",
       "1       0  Jahrelang war eine Rückkehr der Wohnschiffe fü...   \n",
       "2       0  Man kann s ja mal versuchen Die Chemnitzer Woh...   \n",
       "3       0  Jetzt wird es Ernst an der ehemaligen Gerhart ...   \n",
       "4       0  Im Streit um die besetzte Flüchtlings Schule i...   \n",
       "\n",
       "                                          text_split  \n",
       "0  [Sehen gut aus und tun Gutes Die Bremer Kult T...  \n",
       "1  [Jahrelang war eine Rückkehr der Wohnschiffe f...  \n",
       "2  [Man kann s ja mal versuchen Die Chemnitzer Wo...  \n",
       "3  [Jetzt wird es Ernst an der ehemaligen Gerhart...  \n",
       "4  [Im Streit um die besetzte Flüchtlings Schule ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_split'] = df[\"text_cleaned\"].apply(get_split)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out dataframe with the 200-word-sequences as pickle in order to reserve the list structure in the column \"text_split\": \n",
    "\n",
    "df.to_pickle(\"doc_as_200word_seq.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = []\n",
    "label_sequences = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    for seq in row['text_split']:\n",
    "        train_sequences.append(seq)\n",
    "        label_sequences.append(row['source'])\n",
    "        \n",
    "df_sequences = pd.DataFrame({\"sequence\": train_sequences, \"label\": label_sequences})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45402, 2)\n",
      "0    18131\n",
      "1    17641\n",
      "2     9630\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sehen gut aus und tun Gutes Die Bremer Kult Ta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jahrelang war eine Rückkehr der Wohnschiffe fü...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Man kann s ja mal versuchen Die Chemnitzer Woh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jetzt wird es Ernst an der ehemaligen Gerhart ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sie sonst das Haus mit Benzin anzünden Am Nach...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence  label\n",
       "0  Sehen gut aus und tun Gutes Die Bremer Kult Ta...      0\n",
       "1  Jahrelang war eine Rückkehr der Wohnschiffe fü...      0\n",
       "2  Man kann s ja mal versuchen Die Chemnitzer Woh...      0\n",
       "3  Jetzt wird es Ernst an der ehemaligen Gerhart ...      0\n",
       "4  sie sonst das Haus mit Benzin anzünden Am Nach...      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_sequences.shape)\n",
    "print(df_sequences[\"label\"].value_counts())\n",
    "df_sequences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_sequences[\"sequence\"].values\n",
    "y = df_sequences[\"label\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Prepare Data for BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Define Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximal length of input sequence\n",
    "MAX_LEN = 372\n",
    "\n",
    "# Specifying batch size: For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32.\n",
    "batch_size = 16 \n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-german-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  372\n"
     ]
    }
   ],
   "source": [
    "# Run a sample tokenization on all sequences in the training set to get the max_len\n",
    "#max_len = 0\n",
    "\n",
    "#for text in X_train:\n",
    " #   input_ids = tokenizer.encode(text, \n",
    "  #                               add_special_tokens=True)\n",
    "   # max_len = max(max_len, len(input_ids))\n",
    "\n",
    "#print('Max sentence length: ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with tokenization.\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every text...\n",
    "#for text in X_train:\n",
    "for text in X:\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the text.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        text,                      # Sentence to encode.\n",
    "        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "        padding = \"max_length\",\n",
    "        truncation = True,\n",
    "        max_length = MAX_LEN,\n",
    "        return_attention_mask = True,\n",
    "        return_tensors = 'pt'\n",
    "    )\n",
    "    \n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "    \n",
    "    # ----- Qi: Only for checking the results of tokenization\n",
    "    #print(text)\n",
    "    #print(tokenizer.convert_ids_to_tokens(encoded_dict['input_ids'][0])) \n",
    "    #print(len(tokenizer.convert_ids_to_tokens(encoded_dict['input_ids'][0])))\n",
    "    #print(\"-----\") \n",
    "    \n",
    "print(\"Done with tokenization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "# labels = torch.tensor(y_train)\n",
    "labels = torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training and validation set:\n",
      "torch.Size([36321, 372])\n",
      "torch.Size([36321])\n",
      "torch.Size([9081, 372])\n",
      "torch.Size([9081])\n",
      "\n",
      "Shape of attention masks:\n",
      "36321\n",
      "9081\n"
     ]
    }
   ],
   "source": [
    "# Use 80% for training and 20% for validation.\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, random_state=2018, test_size=0.2)\n",
    "\n",
    "# Do the same for the masks.\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels, random_state=2018, test_size=0.2)\n",
    "\n",
    "print(\"Shape of training and validation set:\")\n",
    "print(train_inputs.shape)\n",
    "print(train_labels.shape)\n",
    "print(validation_inputs.shape)\n",
    "print(validation_labels.shape)\n",
    "\n",
    "print(\"\\nShape of attention masks:\")\n",
    "print(len(train_masks))\n",
    "print(len(validation_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Fine-Tuning BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-german-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-german-cased\", \n",
    "    num_labels = 3, # The number of output labels--2 for binary classification. You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Optimizer & Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5,   # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8   # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "# Helper function for formatting elapsed times.\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  2,271.    Elapsed: 0:00:21.\n",
      "  Batch    80  of  2,271.    Elapsed: 0:00:42.\n",
      "  Batch   120  of  2,271.    Elapsed: 0:01:03.\n",
      "  Batch   160  of  2,271.    Elapsed: 0:01:24.\n",
      "  Batch   200  of  2,271.    Elapsed: 0:01:45.\n",
      "  Batch   240  of  2,271.    Elapsed: 0:02:06.\n",
      "  Batch   280  of  2,271.    Elapsed: 0:02:27.\n",
      "  Batch   320  of  2,271.    Elapsed: 0:02:48.\n",
      "  Batch   360  of  2,271.    Elapsed: 0:03:09.\n",
      "  Batch   400  of  2,271.    Elapsed: 0:03:30.\n",
      "  Batch   440  of  2,271.    Elapsed: 0:03:51.\n",
      "  Batch   480  of  2,271.    Elapsed: 0:04:12.\n",
      "  Batch   520  of  2,271.    Elapsed: 0:04:33.\n",
      "  Batch   560  of  2,271.    Elapsed: 0:04:54.\n",
      "  Batch   600  of  2,271.    Elapsed: 0:05:15.\n",
      "  Batch   640  of  2,271.    Elapsed: 0:05:36.\n",
      "  Batch   680  of  2,271.    Elapsed: 0:05:57.\n",
      "  Batch   720  of  2,271.    Elapsed: 0:06:18.\n",
      "  Batch   760  of  2,271.    Elapsed: 0:06:39.\n",
      "  Batch   800  of  2,271.    Elapsed: 0:07:00.\n",
      "  Batch   840  of  2,271.    Elapsed: 0:07:21.\n",
      "  Batch   880  of  2,271.    Elapsed: 0:07:42.\n",
      "  Batch   920  of  2,271.    Elapsed: 0:08:03.\n",
      "  Batch   960  of  2,271.    Elapsed: 0:08:24.\n",
      "  Batch 1,000  of  2,271.    Elapsed: 0:08:45.\n",
      "  Batch 1,040  of  2,271.    Elapsed: 0:09:06.\n",
      "  Batch 1,080  of  2,271.    Elapsed: 0:09:27.\n",
      "  Batch 1,120  of  2,271.    Elapsed: 0:09:48.\n",
      "  Batch 1,160  of  2,271.    Elapsed: 0:10:09.\n",
      "  Batch 1,200  of  2,271.    Elapsed: 0:10:30.\n",
      "  Batch 1,240  of  2,271.    Elapsed: 0:10:51.\n",
      "  Batch 1,280  of  2,271.    Elapsed: 0:11:12.\n",
      "  Batch 1,320  of  2,271.    Elapsed: 0:11:33.\n",
      "  Batch 1,360  of  2,271.    Elapsed: 0:11:54.\n",
      "  Batch 1,400  of  2,271.    Elapsed: 0:12:15.\n",
      "  Batch 1,440  of  2,271.    Elapsed: 0:12:36.\n",
      "  Batch 1,480  of  2,271.    Elapsed: 0:12:57.\n",
      "  Batch 1,520  of  2,271.    Elapsed: 0:13:18.\n",
      "  Batch 1,560  of  2,271.    Elapsed: 0:13:39.\n",
      "  Batch 1,600  of  2,271.    Elapsed: 0:14:00.\n",
      "  Batch 1,640  of  2,271.    Elapsed: 0:14:21.\n",
      "  Batch 1,680  of  2,271.    Elapsed: 0:14:42.\n",
      "  Batch 1,720  of  2,271.    Elapsed: 0:15:03.\n",
      "  Batch 1,760  of  2,271.    Elapsed: 0:15:24.\n",
      "  Batch 1,800  of  2,271.    Elapsed: 0:15:45.\n",
      "  Batch 1,840  of  2,271.    Elapsed: 0:16:06.\n",
      "  Batch 1,880  of  2,271.    Elapsed: 0:16:27.\n",
      "  Batch 1,920  of  2,271.    Elapsed: 0:16:48.\n",
      "  Batch 1,960  of  2,271.    Elapsed: 0:17:09.\n",
      "  Batch 2,000  of  2,271.    Elapsed: 0:17:30.\n",
      "  Batch 2,040  of  2,271.    Elapsed: 0:17:51.\n",
      "  Batch 2,080  of  2,271.    Elapsed: 0:18:12.\n",
      "  Batch 2,120  of  2,271.    Elapsed: 0:18:33.\n",
      "  Batch 2,160  of  2,271.    Elapsed: 0:18:54.\n",
      "  Batch 2,200  of  2,271.    Elapsed: 0:19:15.\n",
      "  Batch 2,240  of  2,271.    Elapsed: 0:19:36.\n",
      "\n",
      "  Average training loss: 0.54\n",
      "  Training epoch took: 0:19:52\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.83\n",
      "  Validation took: 0:01:39\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  2,271.    Elapsed: 0:00:21.\n",
      "  Batch    80  of  2,271.    Elapsed: 0:00:42.\n",
      "  Batch   120  of  2,271.    Elapsed: 0:01:03.\n",
      "  Batch   160  of  2,271.    Elapsed: 0:01:23.\n",
      "  Batch   200  of  2,271.    Elapsed: 0:01:44.\n",
      "  Batch   240  of  2,271.    Elapsed: 0:02:05.\n",
      "  Batch   280  of  2,271.    Elapsed: 0:02:26.\n",
      "  Batch   320  of  2,271.    Elapsed: 0:02:47.\n",
      "  Batch   360  of  2,271.    Elapsed: 0:03:08.\n",
      "  Batch   400  of  2,271.    Elapsed: 0:03:29.\n",
      "  Batch   440  of  2,271.    Elapsed: 0:03:50.\n",
      "  Batch   480  of  2,271.    Elapsed: 0:04:11.\n",
      "  Batch   520  of  2,271.    Elapsed: 0:04:32.\n",
      "  Batch   560  of  2,271.    Elapsed: 0:04:53.\n",
      "  Batch   600  of  2,271.    Elapsed: 0:05:14.\n",
      "  Batch   640  of  2,271.    Elapsed: 0:05:35.\n",
      "  Batch   680  of  2,271.    Elapsed: 0:05:56.\n",
      "  Batch   720  of  2,271.    Elapsed: 0:06:17.\n",
      "  Batch   760  of  2,271.    Elapsed: 0:06:38.\n",
      "  Batch   800  of  2,271.    Elapsed: 0:06:59.\n",
      "  Batch   840  of  2,271.    Elapsed: 0:07:20.\n",
      "  Batch   880  of  2,271.    Elapsed: 0:07:41.\n",
      "  Batch   920  of  2,271.    Elapsed: 0:08:02.\n",
      "  Batch   960  of  2,271.    Elapsed: 0:08:23.\n",
      "  Batch 1,000  of  2,271.    Elapsed: 0:08:44.\n",
      "  Batch 1,040  of  2,271.    Elapsed: 0:09:05.\n",
      "  Batch 1,080  of  2,271.    Elapsed: 0:09:26.\n",
      "  Batch 1,120  of  2,271.    Elapsed: 0:09:47.\n",
      "  Batch 1,160  of  2,271.    Elapsed: 0:10:08.\n",
      "  Batch 1,200  of  2,271.    Elapsed: 0:10:29.\n",
      "  Batch 1,240  of  2,271.    Elapsed: 0:10:50.\n",
      "  Batch 1,280  of  2,271.    Elapsed: 0:11:11.\n",
      "  Batch 1,320  of  2,271.    Elapsed: 0:11:32.\n",
      "  Batch 1,360  of  2,271.    Elapsed: 0:11:53.\n",
      "  Batch 1,400  of  2,271.    Elapsed: 0:12:14.\n",
      "  Batch 1,440  of  2,271.    Elapsed: 0:12:35.\n",
      "  Batch 1,480  of  2,271.    Elapsed: 0:12:56.\n",
      "  Batch 1,520  of  2,271.    Elapsed: 0:13:17.\n",
      "  Batch 1,560  of  2,271.    Elapsed: 0:13:38.\n",
      "  Batch 1,600  of  2,271.    Elapsed: 0:13:58.\n",
      "  Batch 1,640  of  2,271.    Elapsed: 0:14:19.\n",
      "  Batch 1,680  of  2,271.    Elapsed: 0:14:40.\n",
      "  Batch 1,720  of  2,271.    Elapsed: 0:15:01.\n",
      "  Batch 1,760  of  2,271.    Elapsed: 0:15:22.\n",
      "  Batch 1,800  of  2,271.    Elapsed: 0:15:43.\n",
      "  Batch 1,840  of  2,271.    Elapsed: 0:16:04.\n",
      "  Batch 1,880  of  2,271.    Elapsed: 0:16:25.\n",
      "  Batch 1,920  of  2,271.    Elapsed: 0:16:46.\n",
      "  Batch 1,960  of  2,271.    Elapsed: 0:17:07.\n",
      "  Batch 2,000  of  2,271.    Elapsed: 0:17:28.\n",
      "  Batch 2,040  of  2,271.    Elapsed: 0:17:49.\n",
      "  Batch 2,080  of  2,271.    Elapsed: 0:18:10.\n",
      "  Batch 2,120  of  2,271.    Elapsed: 0:18:31.\n",
      "  Batch 2,160  of  2,271.    Elapsed: 0:18:52.\n",
      "  Batch 2,200  of  2,271.    Elapsed: 0:19:13.\n",
      "  Batch 2,240  of  2,271.    Elapsed: 0:19:34.\n",
      "\n",
      "  Average training loss: 0.30\n",
      "  Training epoch took: 0:19:50\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.85\n",
      "  Validation took: 0:01:39\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  2,271.    Elapsed: 0:00:21.\n",
      "  Batch    80  of  2,271.    Elapsed: 0:00:42.\n",
      "  Batch   120  of  2,271.    Elapsed: 0:01:03.\n",
      "  Batch   160  of  2,271.    Elapsed: 0:01:24.\n",
      "  Batch   200  of  2,271.    Elapsed: 0:01:45.\n",
      "  Batch   240  of  2,271.    Elapsed: 0:02:06.\n",
      "  Batch   280  of  2,271.    Elapsed: 0:02:27.\n",
      "  Batch   320  of  2,271.    Elapsed: 0:02:48.\n",
      "  Batch   360  of  2,271.    Elapsed: 0:03:09.\n",
      "  Batch   400  of  2,271.    Elapsed: 0:03:30.\n",
      "  Batch   440  of  2,271.    Elapsed: 0:03:50.\n",
      "  Batch   480  of  2,271.    Elapsed: 0:04:11.\n",
      "  Batch   520  of  2,271.    Elapsed: 0:04:32.\n",
      "  Batch   560  of  2,271.    Elapsed: 0:04:53.\n",
      "  Batch   600  of  2,271.    Elapsed: 0:05:14.\n",
      "  Batch   640  of  2,271.    Elapsed: 0:05:35.\n",
      "  Batch   680  of  2,271.    Elapsed: 0:05:56.\n",
      "  Batch   720  of  2,271.    Elapsed: 0:06:17.\n",
      "  Batch   760  of  2,271.    Elapsed: 0:06:38.\n",
      "  Batch   800  of  2,271.    Elapsed: 0:06:59.\n",
      "  Batch   840  of  2,271.    Elapsed: 0:07:20.\n",
      "  Batch   880  of  2,271.    Elapsed: 0:07:41.\n",
      "  Batch   920  of  2,271.    Elapsed: 0:08:02.\n",
      "  Batch   960  of  2,271.    Elapsed: 0:08:23.\n",
      "  Batch 1,000  of  2,271.    Elapsed: 0:08:44.\n",
      "  Batch 1,040  of  2,271.    Elapsed: 0:09:05.\n",
      "  Batch 1,080  of  2,271.    Elapsed: 0:09:26.\n",
      "  Batch 1,120  of  2,271.    Elapsed: 0:09:47.\n",
      "  Batch 1,160  of  2,271.    Elapsed: 0:10:08.\n",
      "  Batch 1,200  of  2,271.    Elapsed: 0:10:29.\n",
      "  Batch 1,240  of  2,271.    Elapsed: 0:10:50.\n",
      "  Batch 1,280  of  2,271.    Elapsed: 0:11:11.\n",
      "  Batch 1,320  of  2,271.    Elapsed: 0:11:32.\n",
      "  Batch 1,360  of  2,271.    Elapsed: 0:11:53.\n",
      "  Batch 1,400  of  2,271.    Elapsed: 0:12:14.\n",
      "  Batch 1,440  of  2,271.    Elapsed: 0:12:35.\n",
      "  Batch 1,480  of  2,271.    Elapsed: 0:12:56.\n",
      "  Batch 1,520  of  2,271.    Elapsed: 0:13:17.\n",
      "  Batch 1,560  of  2,271.    Elapsed: 0:13:38.\n",
      "  Batch 1,600  of  2,271.    Elapsed: 0:13:59.\n",
      "  Batch 1,640  of  2,271.    Elapsed: 0:14:20.\n",
      "  Batch 1,680  of  2,271.    Elapsed: 0:14:41.\n",
      "  Batch 1,720  of  2,271.    Elapsed: 0:15:02.\n",
      "  Batch 1,760  of  2,271.    Elapsed: 0:15:23.\n",
      "  Batch 1,800  of  2,271.    Elapsed: 0:15:44.\n",
      "  Batch 1,840  of  2,271.    Elapsed: 0:16:04.\n",
      "  Batch 1,880  of  2,271.    Elapsed: 0:16:25.\n",
      "  Batch 1,920  of  2,271.    Elapsed: 0:16:46.\n",
      "  Batch 1,960  of  2,271.    Elapsed: 0:17:07.\n",
      "  Batch 2,000  of  2,271.    Elapsed: 0:17:28.\n",
      "  Batch 2,040  of  2,271.    Elapsed: 0:17:49.\n",
      "  Batch 2,080  of  2,271.    Elapsed: 0:18:10.\n",
      "  Batch 2,120  of  2,271.    Elapsed: 0:18:31.\n",
      "  Batch 2,160  of  2,271.    Elapsed: 0:18:52.\n",
      "  Batch 2,200  of  2,271.    Elapsed: 0:19:13.\n",
      "  Batch 2,240  of  2,271.    Elapsed: 0:19:34.\n",
      "\n",
      "  Average training loss: 0.16\n",
      "  Training epoch took: 0:19:50\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.86\n",
      "  Validation took: 0:01:39\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  2,271.    Elapsed: 0:00:21.\n",
      "  Batch    80  of  2,271.    Elapsed: 0:00:42.\n",
      "  Batch   120  of  2,271.    Elapsed: 0:01:03.\n",
      "  Batch   160  of  2,271.    Elapsed: 0:01:24.\n",
      "  Batch   200  of  2,271.    Elapsed: 0:01:44.\n",
      "  Batch   240  of  2,271.    Elapsed: 0:02:05.\n",
      "  Batch   280  of  2,271.    Elapsed: 0:02:26.\n",
      "  Batch   320  of  2,271.    Elapsed: 0:02:47.\n",
      "  Batch   360  of  2,271.    Elapsed: 0:03:08.\n",
      "  Batch   400  of  2,271.    Elapsed: 0:03:29.\n",
      "  Batch   440  of  2,271.    Elapsed: 0:03:50.\n",
      "  Batch   480  of  2,271.    Elapsed: 0:04:11.\n",
      "  Batch   520  of  2,271.    Elapsed: 0:04:32.\n",
      "  Batch   560  of  2,271.    Elapsed: 0:04:53.\n",
      "  Batch   600  of  2,271.    Elapsed: 0:05:14.\n",
      "  Batch   640  of  2,271.    Elapsed: 0:05:35.\n",
      "  Batch   680  of  2,271.    Elapsed: 0:05:56.\n",
      "  Batch   720  of  2,271.    Elapsed: 0:06:17.\n",
      "  Batch   760  of  2,271.    Elapsed: 0:06:37.\n",
      "  Batch   800  of  2,271.    Elapsed: 0:06:58.\n",
      "  Batch   840  of  2,271.    Elapsed: 0:07:19.\n",
      "  Batch   880  of  2,271.    Elapsed: 0:07:40.\n",
      "  Batch   920  of  2,271.    Elapsed: 0:08:01.\n",
      "  Batch   960  of  2,271.    Elapsed: 0:08:22.\n",
      "  Batch 1,000  of  2,271.    Elapsed: 0:08:43.\n",
      "  Batch 1,040  of  2,271.    Elapsed: 0:09:04.\n",
      "  Batch 1,080  of  2,271.    Elapsed: 0:09:25.\n",
      "  Batch 1,120  of  2,271.    Elapsed: 0:09:46.\n",
      "  Batch 1,160  of  2,271.    Elapsed: 0:10:07.\n",
      "  Batch 1,200  of  2,271.    Elapsed: 0:10:28.\n",
      "  Batch 1,240  of  2,271.    Elapsed: 0:10:49.\n",
      "  Batch 1,280  of  2,271.    Elapsed: 0:11:10.\n",
      "  Batch 1,320  of  2,271.    Elapsed: 0:11:31.\n",
      "  Batch 1,360  of  2,271.    Elapsed: 0:11:52.\n",
      "  Batch 1,400  of  2,271.    Elapsed: 0:12:13.\n",
      "  Batch 1,440  of  2,271.    Elapsed: 0:12:34.\n",
      "  Batch 1,480  of  2,271.    Elapsed: 0:12:55.\n",
      "  Batch 1,520  of  2,271.    Elapsed: 0:13:16.\n",
      "  Batch 1,560  of  2,271.    Elapsed: 0:13:37.\n",
      "  Batch 1,600  of  2,271.    Elapsed: 0:13:58.\n",
      "  Batch 1,640  of  2,271.    Elapsed: 0:14:18.\n",
      "  Batch 1,680  of  2,271.    Elapsed: 0:14:39.\n",
      "  Batch 1,720  of  2,271.    Elapsed: 0:15:00.\n",
      "  Batch 1,760  of  2,271.    Elapsed: 0:15:21.\n",
      "  Batch 1,800  of  2,271.    Elapsed: 0:15:42.\n",
      "  Batch 1,840  of  2,271.    Elapsed: 0:16:03.\n",
      "  Batch 1,880  of  2,271.    Elapsed: 0:16:24.\n",
      "  Batch 1,920  of  2,271.    Elapsed: 0:16:45.\n",
      "  Batch 1,960  of  2,271.    Elapsed: 0:17:06.\n",
      "  Batch 2,000  of  2,271.    Elapsed: 0:17:27.\n",
      "  Batch 2,040  of  2,271.    Elapsed: 0:17:48.\n",
      "  Batch 2,080  of  2,271.    Elapsed: 0:18:09.\n",
      "  Batch 2,120  of  2,271.    Elapsed: 0:18:30.\n",
      "  Batch 2,160  of  2,271.    Elapsed: 0:18:51.\n",
      "  Batch 2,200  of  2,271.    Elapsed: 0:19:12.\n",
      "  Batch 2,240  of  2,271.    Elapsed: 0:19:33.\n",
      "\n",
      "  Average training loss: 0.08\n",
      "  Training epoch took: 0:19:48\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.87\n",
      "  Validation took: 0:01:39\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training vs. test \n",
    "    # (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a backward pass. \n",
    "        # PyTorch doesn't do this automatically because accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # This will return the loss (rather than the model output) because we have provided the `labels`.\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        # The call to `model` always returns a tuple, so we need to pull the loss value out of the tuple.\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can calculate the average loss at the end. \n",
    "        # `loss` is a Tensor containing a single value; the `.item()` function just returns the Python value from the tensor.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # This will return the logits rather than the loss because we have not provided labels.\n",
    "            # token_type_ids is the same as the \"segment ids\", which differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        # Get the \"logits\" output by the model. The \"logits\" are the output values prior to applying an activation function like the softmax.\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to /work/qi.yu/output/bert/ft_models/ft_on_200wordseqs_2022-01-26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/work/qi.yu/output/bert/ft_models/ft_on_200wordseqs_2022-01-26/tokenizer_config.json',\n",
       " '/work/qi.yu/output/bert/ft_models/ft_on_200wordseqs_2022-01-26/special_tokens_map.json',\n",
       " '/work/qi.yu/output/bert/ft_models/ft_on_200wordseqs_2022-01-26/vocab.txt',\n",
       " '/work/qi.yu/output/bert/ft_models/ft_on_200wordseqs_2022-01-26/added_tokens.json')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = 'finetuned_BERT_on_200wordseqs'\n",
    "\n",
    "print(\"Saving model to %s\" % output_dir)\n",
    "\n",
    "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "# They can then be reloaded using `from_pretrained()`\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
